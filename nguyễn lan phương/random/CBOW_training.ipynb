{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ý tưởng siêu chi tiết của CBOW\n",
    "\n",
    "### 1. Cách xây dựng dữ liệu huấn luyện  \n",
    "- Với mỗi từ trong tập dữ liệu, ta lấy `window_size` từ bên trái và `window_size` từ bên phải.  \n",
    "- Tập hợp các từ này tạo thành một ngữ cảnh (`context_length = window_size * 2`).  \n",
    "- Nhãn (`label`) cho ngữ cảnh này chính là từ trung tâm ban đầu.  \n",
    "\n",
    "### 2. Mô hình mạng nơ-ron  \n",
    "\n",
    "Mô hình huấn luyện gồm các lớp sau:  \n",
    "\n",
    "1. **Lớp đầu tiên (Embedding Layer)**:  \n",
    "   - Đầu vào: `(batch_size, context_length)`, chứa các chỉ mục (index) của từ ngữ cảnh.  \n",
    "   - Dùng ma trận nhúng **Embedding Matrix** có kích thước `(vocab_length, embedding_dim)`, trong đó:  \n",
    "     - `vocab_length`: Kích thước từ vựng.  \n",
    "     - `embedding_dim`: Kích thước vector nhúng của mỗi từ.  \n",
    "   - Các chỉ mục đầu vào được ánh xạ thành vector nhúng, tạo ra đầu ra có dạng `(batch_size, context_length, embedding_dim)`.  \n",
    "   - **Nguồn gốc của ma trận embedding**:  \n",
    "     - Ban đầu, ma trận này có thể được khởi tạo ngẫu nhiên.  \n",
    "     - Trong quá trình huấn luyện, nó sẽ được cập nhật thông qua lan truyền ngược (backpropagation).  \n",
    "     - Nếu dùng mô hình đã được huấn luyện sẵn (pretrained embeddings, ví dụ: Word2Vec, GloVe), ta có thể nạp các giá trị nhúng này vào ma trận và có thể cố định hoặc tiếp tục tinh chỉnh.  \n",
    "\n",
    "2. **Lớp thứ hai (Average Layer)**:  \n",
    "   - Lấy trung bình các vector nhúng theo chiều `context_length`, kết quả có dạng `(batch_size, embedding_dim)`.  \n",
    "\n",
    "3. **Lớp thứ ba (Output Layer)**:  \n",
    "   - Đầu ra có kích thước `(batch_size, vocab_length)`, sử dụng hàm softmax để dự đoán từ trung tâm (`target_word`).  \n",
    "\n",
    "### 3. Cách hoạt động  \n",
    "- Mô hình sẽ học cách ánh xạ từ ngữ cảnh sang từ trung tâm bằng cách điều chỉnh ma trận embedding sao cho các từ có ngữ cảnh tương tự sẽ có vector nhúng gần nhau.  \n",
    "- Sau khi huấn luyện xong, ta có thể sử dụng ma trận embedding này để biểu diễn từ vựng trong các bài toán NLP khác.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('sarcasm.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['The sky is blue and beautiful.',\n",
    "          'Love this blue and beautiful sky!',\n",
    "          'The quick brown fox jumps over the lazy dog.',\n",
    "          \"A king's breakfast has sausages, ham, bacon, eggs, toast and beans\",\n",
    "          'I love green eggs, ham, sausages and bacon!',\n",
    "          'The brown fox is quick and the blue dog is lazy!',\n",
    "          'The sky is very blue and the sky is very beautiful today',\n",
    "          'The dog is lazy but the brown fox is quick!'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import text\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "tokenizer = text.Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "word2id = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'is': 2,\n",
       " 'and': 3,\n",
       " 'sky': 4,\n",
       " 'blue': 5,\n",
       " 'beautiful': 6,\n",
       " 'quick': 7,\n",
       " 'brown': 8,\n",
       " 'fox': 9,\n",
       " 'lazy': 10,\n",
       " 'dog': 11,\n",
       " 'love': 12,\n",
       " 'sausages': 13,\n",
       " 'ham': 14,\n",
       " 'bacon': 15,\n",
       " 'eggs': 16,\n",
       " 'very': 17,\n",
       " 'this': 18,\n",
       " 'jumps': 19,\n",
       " 'over': 20,\n",
       " 'a': 21,\n",
       " \"king's\": 22,\n",
       " 'breakfast': 23,\n",
       " 'has': 24,\n",
       " 'toast': 25,\n",
       " 'beans': 26,\n",
       " 'i': 27,\n",
       " 'green': 28,\n",
       " 'today': 29,\n",
       " 'but': 30}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id['<PAD>'] = 0\n",
    "id2word = {v: k for k, v in word2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 4, 2, 5, 3, 6],\n",
       " [12, 18, 5, 3, 6, 4],\n",
       " [1, 7, 8, 9, 19, 20, 1, 10, 11],\n",
       " [21, 22, 23, 24, 13, 14, 15, 16, 25, 3, 26],\n",
       " [27, 12, 28, 16, 14, 13, 3, 15],\n",
       " [1, 8, 9, 2, 7, 3, 1, 5, 11, 2, 10],\n",
       " [1, 4, 2, 17, 5, 3, 1, 4, 2, 17, 6, 29],\n",
       " [1, 11, 2, 10, 30, 1, 8, 9, 2, 7]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wids = [[word2id[w] for w in text.text_to_word_sequence(c)] for c in corpus]\n",
    "wids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 31\n",
      "Vocabulary Sample: [('the', 1), ('is', 2), ('and', 3), ('sky', 4), ('blue', 5), ('beautiful', 6), ('quick', 7), ('brown', 8), ('fox', 9), ('lazy', 10)]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word2id)\n",
    "embed_size = 300\n",
    "window_size = 2 # context window size\n",
    "\n",
    "print('Vocabulary Size:', vocab_size)\n",
    "print('Vocabulary Sample:', list(word2id.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_context_word_pairs(corpus, window_size, vocab_size):\n",
    "    context_length = window_size * 2\n",
    "    for words in corpus:\n",
    "        sentence_length = len(words)\n",
    "        for index, word in enumerate(words):\n",
    "            context_words = []\n",
    "            label_word = []\n",
    "            start = index - window_size\n",
    "            end = index + window_size + 1\n",
    "\n",
    "            context_words.append([\n",
    "                words[i] \n",
    "                for i in range(start, end)\n",
    "                if 0 <= i < sentence_length\n",
    "                and i != index\n",
    "            ])\n",
    "\n",
    "            label_word.append(word)\n",
    "\n",
    "            x = sequence.pad_sequences(context_words, maxlen=context_length)\n",
    "            y = to_categorical(label_word, num_classes=vocab_size)\n",
    "            \n",
    "            yield (x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = generate_context_word_pairs(corpus=wids, window_size=window_size, vocab_size=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object generate_context_word_pairs at 0x000001F9ACBFEC40>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 4 5 3]] [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0.]]\n",
      "Context (X): ['the', 'sky', 'blue', 'and'] -> Target (Y): is\n",
      "[[4 2 3 6]] [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0.]]\n",
      "Context (X): ['sky', 'is', 'and', 'beautiful'] -> Target (Y): blue\n",
      "[[12 18  3  6]] [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0.]]\n",
      "Context (X): ['love', 'this', 'and', 'beautiful'] -> Target (Y): blue\n",
      "[[18  5  6  4]] [[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0.]]\n",
      "Context (X): ['this', 'blue', 'beautiful', 'sky'] -> Target (Y): and\n",
      "[[ 1  7  9 19]] [[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0.]]\n",
      "Context (X): ['the', 'quick', 'fox', 'jumps'] -> Target (Y): brown\n",
      "[[ 7  8 19 20]] [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0.]]\n",
      "Context (X): ['quick', 'brown', 'jumps', 'over'] -> Target (Y): fox\n",
      "[[ 8  9 20  1]] [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0.]]\n",
      "Context (X): ['brown', 'fox', 'over', 'the'] -> Target (Y): jumps\n",
      "[[ 9 19  1 10]] [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0.]]\n",
      "Context (X): ['fox', 'jumps', 'the', 'lazy'] -> Target (Y): over\n",
      "[[19 20 10 11]] [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0.]]\n",
      "Context (X): ['jumps', 'over', 'lazy', 'dog'] -> Target (Y): the\n",
      "[[21 22 24 13]] [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 0.]]\n",
      "Context (X): ['a', \"king's\", 'has', 'sausages'] -> Target (Y): breakfast\n",
      "[[22 23 13 14]] [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0.]]\n",
      "Context (X): [\"king's\", 'breakfast', 'sausages', 'ham'] -> Target (Y): has\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "i = 0\n",
    "for x, y in generate_context_word_pairs(corpus=wids, window_size=window_size, vocab_size=vocab_size):\n",
    "    if 0 not in x[0]:\n",
    "        print(x, y)\n",
    "        print('Context (X):', [id2word[w] for w in x[0]], '-> Target (Y):', id2word[np.argwhere(y[0])[0][0]])\n",
    "\n",
    "        if i == 10:\n",
    "            break\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tuan Linh\\miniconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_2 (\u001b[38;5;33mLambda\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Lambda\n",
    "\n",
    "# build CBOW architecture\n",
    "cbow = Sequential()\n",
    "cbow.add(Embedding(input_dim=vocab_size, output_dim=embed_size, input_length=window_size*2))\n",
    "# Output ra 4 vector: (batch_size, 4, 300)\n",
    "cbow.add(Lambda(lambda x: K.mean(x, axis=1), output_shape=(embed_size,)))\n",
    "# Output ra 4 vector: (batch_size, 300)\n",
    "cbow.add(Dense(vocab_size, activation='softmax'))\n",
    "# Output ra 4 vector: (batch_size, vocab_size)\n",
    "cbow.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "# view model summary\n",
    "print(cbow.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize model structure\n",
    "from IPython.display import SVG\n",
    "from keras.utils import model_to_dot\n",
    "\n",
    "cbow.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "You must install pydot (`pip install pydot`) for model_to_dot to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m SVG(\u001b[43mmodel_to_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcbow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_shapes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_layer_names\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mrankdir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTB\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m.create(prog=\u001b[33m'\u001b[39m\u001b[33mdot\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mformat\u001b[39m=\u001b[33m'\u001b[39m\u001b[33msvg\u001b[39m\u001b[33m'\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Tuan Linh\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\model_visualization.py:252\u001b[39m, in \u001b[36mmodel_to_dot\u001b[39m\u001b[34m(model, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, dpi, subgraph, show_layer_activations, show_trainable, **kwargs)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;66;03m# from keras.src.layers import Wrapper\u001b[39;00m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_pydot():\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m    253\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou must install pydot (`pip install pydot`) for \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    254\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmodel_to_dot to work.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    255\u001b[39m     )\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m subgraph:\n\u001b[32m    258\u001b[39m     dot = pydot.Cluster(style=\u001b[33m\"\u001b[39m\u001b[33mdashed\u001b[39m\u001b[33m\"\u001b[39m, graph_name=model.name)\n",
      "\u001b[31mImportError\u001b[39m: You must install pydot (`pip install pydot`) for model_to_dot to work."
     ]
    }
   ],
   "source": [
    "SVG(model_to_dot(cbow, show_shapes=True, show_layer_names=False,\n",
    "                 rankdir='TB').create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tLoss: 250.25726\n",
      "\n",
      "Epoch: 2 \tLoss: 246.75287\n",
      "\n",
      "Epoch: 3 \tLoss: 242.3309\n",
      "\n",
      "Epoch: 4 \tLoss: 237.27925\n",
      "\n",
      "Epoch: 5 \tLoss: 231.91743\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 6):\n",
    "    loss = 0.\n",
    "    i = 0\n",
    "    for x, y in generate_context_word_pairs(corpus=wids, window_size=window_size, vocab_size=vocab_size):\n",
    "        i += 1\n",
    "        loss += cbow.train_on_batch(x, y)\n",
    "        if i % 100000 == 0:\n",
    "            print('Processed {} (context, word) pairs'.format(i))\n",
    "\n",
    "    print('Epoch:', epoch, '\\tLoss:', loss)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 300)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>-0.016159</td>\n",
       "      <td>-0.001919</td>\n",
       "      <td>-0.034625</td>\n",
       "      <td>-0.000501</td>\n",
       "      <td>-0.068037</td>\n",
       "      <td>0.039652</td>\n",
       "      <td>-0.073711</td>\n",
       "      <td>-0.056429</td>\n",
       "      <td>0.110851</td>\n",
       "      <td>-0.042928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031391</td>\n",
       "      <td>-0.037141</td>\n",
       "      <td>-0.102580</td>\n",
       "      <td>0.022456</td>\n",
       "      <td>0.040771</td>\n",
       "      <td>-0.004076</td>\n",
       "      <td>-0.028039</td>\n",
       "      <td>-0.095149</td>\n",
       "      <td>-0.023611</td>\n",
       "      <td>-0.011764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>-0.013875</td>\n",
       "      <td>0.041296</td>\n",
       "      <td>0.043127</td>\n",
       "      <td>-0.031687</td>\n",
       "      <td>-0.035261</td>\n",
       "      <td>0.011198</td>\n",
       "      <td>0.001305</td>\n",
       "      <td>0.008456</td>\n",
       "      <td>0.002694</td>\n",
       "      <td>0.041878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045352</td>\n",
       "      <td>-0.039327</td>\n",
       "      <td>0.016409</td>\n",
       "      <td>-0.035324</td>\n",
       "      <td>0.059275</td>\n",
       "      <td>-0.010692</td>\n",
       "      <td>-0.016966</td>\n",
       "      <td>-0.075731</td>\n",
       "      <td>0.011736</td>\n",
       "      <td>0.035353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sky</th>\n",
       "      <td>-0.023439</td>\n",
       "      <td>0.067804</td>\n",
       "      <td>-0.068437</td>\n",
       "      <td>-0.073149</td>\n",
       "      <td>-0.101756</td>\n",
       "      <td>0.029633</td>\n",
       "      <td>-0.005518</td>\n",
       "      <td>0.021309</td>\n",
       "      <td>-0.022604</td>\n",
       "      <td>-0.063910</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039347</td>\n",
       "      <td>0.086150</td>\n",
       "      <td>-0.100598</td>\n",
       "      <td>0.093492</td>\n",
       "      <td>0.099698</td>\n",
       "      <td>-0.006067</td>\n",
       "      <td>0.043246</td>\n",
       "      <td>-0.053052</td>\n",
       "      <td>-0.050908</td>\n",
       "      <td>0.072212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blue</th>\n",
       "      <td>-0.086822</td>\n",
       "      <td>0.025009</td>\n",
       "      <td>0.066076</td>\n",
       "      <td>-0.099671</td>\n",
       "      <td>0.010679</td>\n",
       "      <td>0.078916</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.060186</td>\n",
       "      <td>-0.044301</td>\n",
       "      <td>0.013770</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073872</td>\n",
       "      <td>-0.057893</td>\n",
       "      <td>0.046852</td>\n",
       "      <td>0.046570</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.045964</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>-0.066373</td>\n",
       "      <td>-0.073589</td>\n",
       "      <td>-0.064363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beautiful</th>\n",
       "      <td>-0.053409</td>\n",
       "      <td>0.054269</td>\n",
       "      <td>0.016521</td>\n",
       "      <td>-0.052443</td>\n",
       "      <td>-0.083826</td>\n",
       "      <td>0.083107</td>\n",
       "      <td>-0.072217</td>\n",
       "      <td>0.016962</td>\n",
       "      <td>0.060972</td>\n",
       "      <td>-0.052102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.123333</td>\n",
       "      <td>-0.084623</td>\n",
       "      <td>0.054153</td>\n",
       "      <td>0.084007</td>\n",
       "      <td>0.065160</td>\n",
       "      <td>0.029221</td>\n",
       "      <td>0.015634</td>\n",
       "      <td>-0.096870</td>\n",
       "      <td>-0.058569</td>\n",
       "      <td>0.020105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1         2         3         4         5    \\\n",
       "is        -0.016159 -0.001919 -0.034625 -0.000501 -0.068037  0.039652   \n",
       "and       -0.013875  0.041296  0.043127 -0.031687 -0.035261  0.011198   \n",
       "sky       -0.023439  0.067804 -0.068437 -0.073149 -0.101756  0.029633   \n",
       "blue      -0.086822  0.025009  0.066076 -0.099671  0.010679  0.078916   \n",
       "beautiful -0.053409  0.054269  0.016521 -0.052443 -0.083826  0.083107   \n",
       "\n",
       "                6         7         8         9    ...       290       291  \\\n",
       "is        -0.073711 -0.056429  0.110851 -0.042928  ...  0.031391 -0.037141   \n",
       "and        0.001305  0.008456  0.002694  0.041878  ...  0.045352 -0.039327   \n",
       "sky       -0.005518  0.021309 -0.022604 -0.063910  ... -0.039347  0.086150   \n",
       "blue       0.004387  0.060186 -0.044301  0.013770  ... -0.073872 -0.057893   \n",
       "beautiful -0.072217  0.016962  0.060972 -0.052102  ... -0.123333 -0.084623   \n",
       "\n",
       "                292       293       294       295       296       297  \\\n",
       "is        -0.102580  0.022456  0.040771 -0.004076 -0.028039 -0.095149   \n",
       "and        0.016409 -0.035324  0.059275 -0.010692 -0.016966 -0.075731   \n",
       "sky       -0.100598  0.093492  0.099698 -0.006067  0.043246 -0.053052   \n",
       "blue       0.046852  0.046570  0.050003  0.045964  0.010325 -0.066373   \n",
       "beautiful  0.054153  0.084007  0.065160  0.029221  0.015634 -0.096870   \n",
       "\n",
       "                298       299  \n",
       "is        -0.023611 -0.011764  \n",
       "and        0.011736  0.035353  \n",
       "sky       -0.050908  0.072212  \n",
       "blue      -0.073589 -0.064363  \n",
       "beautiful -0.058569  0.020105  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "weights = cbow.get_weights()[0]\n",
    "weights = weights[1:]\n",
    "print(weights.shape)\n",
    "\n",
    "pd.DataFrame(weights, index=list(id2word.values())[1:]).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
