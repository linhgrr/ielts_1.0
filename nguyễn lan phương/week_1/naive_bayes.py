import math
from collections import defaultdict

# T·∫≠p d·ªØ li·ªáu hu·∫•n luy·ªán
train_data = [
    ("I love this movie", "Positive"),
    ("I hate this movie", "Negative"),
    ("This movie is amazing", "Positive"),
    ("I dislike this film", "Negative"),
    ("Fantastic movie", "Positive"),
    ("Terrible film", "Negative")
]

# Ti·ªÅn x·ª≠ l√Ω: T√°ch t·ª´
def tokenize(sentence):
    return sentence.lower().split()

# ƒê·∫øm s·ªë l∆∞·ª£ng t·ª´ trong t·ª´ng nh√£n
word_counts = {"Positive": defaultdict(int), "Negative": defaultdict(int)}
class_counts = {"Positive": 0, "Negative": 0}
vocab = set()

# Duy·ªát qua d·ªØ li·ªáu hu·∫•n luy·ªán
for sentence, label in train_data:
    words = tokenize(sentence)
    class_counts[label] += 1  # ƒê·∫øm s·ªë c√¢u thu·ªôc t·ª´ng nh√£n
    for word in words:
        word_counts[label][word] += 1  # ƒê·∫øm s·ªë l·∫ßn xu·∫•t hi·ªán c·ªßa t·ª´ trong nh√£n
        vocab.add(word)  # Th√™m t·ª´ v√†o t·ª´ v·ª±ng

# T√≠nh P(C) - X√°c su·∫•t ti√™n nghi·ªám c·ªßa t·ª´ng nh√£n
total_docs = sum(class_counts.values())
priors = {label: class_counts[label] / total_docs for label in class_counts}

# T√≠nh P(w|C) v·ªõi Laplacian Smoothing (Œ± = 1)
alpha = 1
vocab_size = len(vocab)
word_probs = {}

for label in ["Positive", "Negative"]:
    total_words = sum(word_counts[label].values())  # T·ªïng s·ªë t·ª´ trong nh√£n
    word_probs[label] = {
        word: (word_counts[label][word] + alpha) / (total_words + alpha * vocab_size)
        for word in vocab
    }

# H√†m t√≠nh Log-Likelihood
def compute_log_likelihood(sentence):
    words = tokenize(sentence)
    log_likelihoods = {}

    for label in ["Positive", "Negative"]:
        log_likelihoods[label] = math.log(priors[label])  # log P(C)
        for word in words:
            if word in word_probs[label]:  # Ch·ªâ t√≠nh nh·ªØng t·ª´ c√≥ trong t·ª´ v·ª±ng
                log_likelihoods[label] += math.log(word_probs[label][word])

    return log_likelihoods

# H√†m ph√¢n lo·∫°i c·∫£m x√∫c
def classify(sentence):
    log_likelihoods = compute_log_likelihood(sentence)
    return max(log_likelihoods, key=log_likelihoods.get)  # Ch·ªçn nh√£n c√≥ log-likelihood cao nh·∫•t

# **üìå TEST: D·ª± ƒëo√°n c·∫£m x√∫c**
test_sentences = [
    "I love this film",
    "This movie is terrible",
    "Fantastic acting",
    "I dislike this movie"
]

for sentence in test_sentences:
    print(f"'{sentence}' ‚ûù {classify(sentence)}")
